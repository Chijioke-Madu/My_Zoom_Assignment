{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d114f4a-8bc0-4d27-9d30-75da3fcb67f7",
   "metadata": {},
   "source": [
    "# A model for classifying various hair types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd756f3-6f7d-4e11-b374-79c4f1b9b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95918ce7-4ed7-4c1e-9c89-318db6d17d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "print(torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d259fc-1286-404d-8c63-40aaa3486e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility settings\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f6b345-7e09-4776-9795-434038c3af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(baseCNN, self).__init__()\n",
    "        \n",
    "        # Conv Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # The input size to the linear layer calculation:\n",
    "        # Input: 200x200\n",
    "        # Conv2d (3x3, s=1, p=0) -> (200 - 3)/1 + 1 = 198. Output: 32 x 198 x 198\n",
    "        # MaxPool2d (2x2) -> 198 / 2 = 99. Output: 32 x 99 x 99\n",
    "        # Flatten size = 32 * 99 * 99 = 313,632\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x # We return logits, activation handled by Loss function/Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579fd41-2e9a-4354-8ba9-9e826494ef79",
   "metadata": {},
   "source": [
    "The problem is Binary Classification (1 output neuron).\n",
    "\n",
    "CrossEntropyLoss is typically for Multi-class classification.\n",
    "\n",
    "MSELoss is for regression.\n",
    "\n",
    "The provided training loop code uses torch.sigmoid(outputs) to calculate accuracy. This implies the model outputs \"logits\" (raw scores) rather than probabilities. The most numerically stable loss function that takes logits and applies Sigmoid internally is BCEWithLogitsLoss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897557a-da62-49c1-a17e-dfb2bee7cb6e",
   "metadata": {},
   "source": [
    "*The total number of parameters of the model*\n",
    "Answer: 20073473\n",
    "\n",
    "* Calculation:\n",
    "\n",
    "* Conv2d: (3 * 3 * 3 + 1) * 32 = 28 * 32 = 896 parameters. (kernel_h * kernel_w * input_channels + bias) * output_channels\n",
    "\n",
    "* Linear 1: Input size is 32 * 99 * 99 = 313,632. \n",
    "\n",
    "* Weights: 313,632 * 64 = 20,072,448. Bias: 64. Total: 20,072,512.\n",
    "\n",
    "* Linear 2: 64 * 1 (weights) + 1 (bias) = 65.\n",
    "\n",
    "* Total: 896 + 20,072,512 + 65 = 20,073,473"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8d98b-48d4-4654-897b-00e91cac4e55",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a249cc-362f-42a0-8ed2-f6cf82e98094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7017ba9f-2cc0-4de4-9564-e869c8cc7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loaders (Assuming data is in './data')\n",
    "train_dataset = datasets.ImageFolder('data/train', transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder('data/test', transform=test_transforms)\n",
    "\n",
    "# Important: Shuffle=True for train, False for test\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a3983c-6ac3-4901-a462-863eba415171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = baseCNN().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a8afc2-2cb6-43f0-a18e-40037d4e24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.6492, Acc: 0.6350\n",
      "Epoch 2/10 - Loss: 0.5565, Acc: 0.7050\n",
      "Epoch 3/10 - Loss: 0.5461, Acc: 0.7200\n",
      "Epoch 4/10 - Loss: 0.4670, Acc: 0.7675\n",
      "Epoch 5/10 - Loss: 0.4307, Acc: 0.7937\n",
      "Epoch 6/10 - Loss: 0.3459, Acc: 0.8438\n",
      "Epoch 7/10 - Loss: 0.2653, Acc: 0.8950\n",
      "Epoch 8/10 - Loss: 0.2238, Acc: 0.9175\n",
      "Epoch 9/10 - Loss: 0.1496, Acc: 0.9413\n",
      "Epoch 10/10 - Loss: 0.1669, Acc: 0.9337\n",
      "--- Results ---\n",
      "Median Training Accuracy: 0.81875\n",
      "Std Dev Training Loss: 0.1668939442085757\n"
     ]
    }
   ],
   "source": [
    "# 4. Training Loop\n",
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(test_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "# --- ANSWERS CALCULATION ---\n",
    "print(\"--- Results ---\")\n",
    "print(f\"Median Training Accuracy: {np.median(history['acc'])}\")\n",
    "print(f\"Std Dev Training Loss: {np.std(history['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba9889d-1ef3-4a38-9b5c-2f46e00f0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Augmentations\n",
    "train_transforms_aug = transforms.Compose([\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((200, 200)), # Ensure size is back to 200 if crop changed it oddly, though RandomResizedCrop handles it\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f26fc80d-0d72-42ca-8168-e021492378ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Reload Training Data with Augmentations\n",
    "train_dataset_aug = datasets.ImageFolder('data/train', transform=train_transforms_aug)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True)\n",
    "\n",
    "# Note: We do NOT re-initialize the model. We continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f401172-f5ba-4390-950f-5bbee9f1be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Augmentation Training...\n",
      "Aug Epoch 1/10 - Val Loss: 0.5951, Val Acc: 0.6915\n",
      "Aug Epoch 2/10 - Val Loss: 0.6738, Val Acc: 0.6866\n",
      "Aug Epoch 3/10 - Val Loss: 0.6871, Val Acc: 0.7114\n",
      "Aug Epoch 4/10 - Val Loss: 0.5586, Val Acc: 0.7065\n",
      "Aug Epoch 5/10 - Val Loss: 0.6166, Val Acc: 0.6667\n",
      "Aug Epoch 6/10 - Val Loss: 0.6021, Val Acc: 0.7065\n",
      "Aug Epoch 7/10 - Val Loss: 0.7201, Val Acc: 0.6318\n",
      "Aug Epoch 8/10 - Val Loss: 0.8214, Val Acc: 0.6418\n",
      "Aug Epoch 9/10 - Val Loss: 0.5524, Val Acc: 0.7363\n",
      "Aug Epoch 10/10 - Val Loss: 0.5431, Val Acc: 0.7313\n",
      "--- Augmentation Results ---\n",
      "Mean Test Loss (All Aug Epochs): 0.6370412064873757\n",
      "Mean Test Acc (Last 5 Epochs): 0.6895522388059703\n"
     ]
    }
   ],
   "source": [
    "# 3. Training Loop (epochs 11-20)\n",
    "num_epochs_aug = 10\n",
    "history_aug = {'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"Starting Augmentation Training...\")\n",
    "\n",
    "for epoch in range(num_epochs_aug):\n",
    "    model.train()\n",
    "    for images, labels in train_loader_aug: # Use new loader\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(test_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history_aug['val_loss'].append(val_epoch_loss)\n",
    "    history_aug['val_acc'].append(val_epoch_acc)\n",
    "    \n",
    "    print(f\"Aug Epoch {epoch+1}/{num_epochs_aug} - Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "# --- ANSWERS CALCULATION ---\n",
    "print(\"--- Augmentation Results ---\")\n",
    "print(f\"Mean Test Loss (All Aug Epochs): {np.mean(history_aug['val_loss'])}\")\n",
    "print(f\"Mean Test Acc (Last 5 Epochs): {np.mean(history_aug['val_acc'][5:])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
